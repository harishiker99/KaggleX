{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":127612,"sourceType":"datasetVersion","datasetId":64826}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-09T17:54:25.589605Z","iopub.execute_input":"2024-11-09T17:54:25.590202Z","iopub.status.idle":"2024-11-09T17:54:25.952008Z","shell.execute_reply.started":"2024-11-09T17:54:25.590163Z","shell.execute_reply":"2024-11-09T17:54:25.951266Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"! pip install accelerate -q\n! pip install -i https://pypi.org/simple/ bitsandbytes -q\n! pip install peft -q\n! pip install trl -q\n! pip install --upgrade huggingface_hub -q\n! pip install git+https://github.com/huggingface/datasets -U -q\n! pip install git+https://github.com/huggingface/transformers -U -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T17:54:25.953902Z","iopub.execute_input":"2024-11-09T17:54:25.954743Z","iopub.status.idle":"2024-11-09T17:56:55.937818Z","shell.execute_reply.started":"2024-11-09T17:54:25.954698Z","shell.execute_reply":"2024-11-09T17:56:55.936524Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\naccess_token_read = user_secrets.get_secret(\"HF_TOKEN\")\nlogin(token = access_token_read)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T17:56:55.939651Z","iopub.execute_input":"2024-11-09T17:56:55.940059Z","iopub.status.idle":"2024-11-09T17:56:56.543286Z","shell.execute_reply.started":"2024-11-09T17:56:55.940012Z","shell.execute_reply":"2024-11-09T17:56:56.542560Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n    GemmaTokenizer,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport torch, wandb\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T17:56:56.544347Z","iopub.execute_input":"2024-11-09T17:56:56.544645Z","iopub.status.idle":"2024-11-09T17:57:15.093033Z","shell.execute_reply.started":"2024-11-09T17:56:56.544606Z","shell.execute_reply":"2024-11-09T17:57:15.092132Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"base_model = \"google/gemma-2-2b\"\ndataset_name = \"harishnair04/mtsamples\"\nnew_model = \"Gemma-medtr-2b-sft-v2\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T17:57:15.096239Z","iopub.execute_input":"2024-11-09T17:57:15.097240Z","iopub.status.idle":"2024-11-09T17:57:15.101116Z","shell.execute_reply.started":"2024-11-09T17:57:15.097203Z","shell.execute_reply":"2024-11-09T17:57:15.100143Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=True,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T17:57:15.102314Z","iopub.execute_input":"2024-11-09T17:57:15.102637Z","iopub.status.idle":"2024-11-09T17:57:15.316247Z","shell.execute_reply.started":"2024-11-09T17:57:15.102600Z","shell.execute_reply":"2024-11-09T17:57:15.315247Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    token=access_token_read\n)\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, token=access_token_read, trust_remote_code=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T17:57:15.317537Z","iopub.execute_input":"2024-11-09T17:57:15.317969Z","iopub.status.idle":"2024-11-09T18:01:36.234909Z","shell.execute_reply.started":"2024-11-09T17:57:15.317924Z","shell.execute_reply":"2024-11-09T18:01:36.233534Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/818 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c3f6a0f29de4062a04de1bbeafb6239"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"604f5f371c204da1a1a1c76f721e3216"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1273ec7864a43a3a0be6453490f6041"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00208c38b5c14eb29bba5d29bde14e0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1d0fe26d1b2419d8cfeff3365853d74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/481M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7758ab1bd4e49a9b3ee077ffc0a07ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f8dcd85a7904572aa2650b04fb78089"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef9661f46f6a4df486ed4b5e4281b341"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/46.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc18d022f0d843ce89c69940e809cb9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"343b6cbb8d7f4b428e0f48fef2f37a30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77887792577e468eb65d913cb6a61f01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b528e1fee16d468594e3c2de4e71b49a"}},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"Fine-tuning the full model will take a lot of time, so to accelerate the training process, we will create and attach the adapter layer, resulting in a faster and more memory-efficient process. ","metadata":{}},{"cell_type":"code","source":"import bitsandbytes as bnb\n\ndef find_all_linear_names(model):\n    cls = bnb.nn.Linear4bit\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names:  # needed for 16 bit\n        lora_module_names.remove('lm_head')\n    return list(lora_module_names)\n\nmodules = find_all_linear_names(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T18:01:36.236366Z","iopub.execute_input":"2024-11-09T18:01:36.236736Z","iopub.status.idle":"2024-11-09T18:01:36.244201Z","shell.execute_reply.started":"2024-11-09T18:01:36.236699Z","shell.execute_reply":"2024-11-09T18:01:36.243402Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# LoRA config\npeft_config = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=modules\n)\nmodel, tokenizer = setup_chat_format(model, tokenizer)\nmodel = get_peft_model(model, peft_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T18:01:36.245428Z","iopub.execute_input":"2024-11-09T18:01:36.245745Z","iopub.status.idle":"2024-11-09T18:01:39.654472Z","shell.execute_reply.started":"2024-11-09T18:01:36.245712Z","shell.execute_reply":"2024-11-09T18:01:39.653630Z"}},"outputs":[{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"Loading the dataset","metadata":{}},{"cell_type":"code","source":"# Importing the dataset\ndataset = load_dataset(dataset_name, split=\"all\")\ndataset = dataset.shuffle(seed=65)\n\ndef format_chat_template(row):\n    # Ensure none of the values are None\n    description = row[\"description\"] if row[\"description\"] is not None else \"\"\n    transcription = row[\"transcription\"] if row[\"transcription\"] is not None else \"\"\n    keywords = row[\"keywords\"] if row[\"keywords\"] is not None else \"\"\n    \n    row_json = [\n        {\"role\": \"system\", \"content\": description},\n        {\"role\": \"user\", \"content\": transcription},\n        {\"role\": \"assistant\", \"content\": keywords}\n    ]\n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row\n\ndataset = dataset.map(\n    format_chat_template,\n    num_proc=4,\n)\n\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T18:01:39.655954Z","iopub.execute_input":"2024-11-09T18:01:39.656275Z","iopub.status.idle":"2024-11-09T18:01:42.858431Z","shell.execute_reply.started":"2024-11-09T18:01:39.656242Z","shell.execute_reply":"2024-11-09T18:01:42.857438Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/31.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f055e2cf3ab4c05bddbd2fb635f6bc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"mtsamples.csv:   0%|          | 0.00/17.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5292dfad6aa84fe6b11b3cfed3027377"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/4999 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f926c328f084dab9c754fedabe23588"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/4999 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b98fe6243fb143f79e55b17f24c40fcc"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Unnamed: 0', 'description', 'medical_specialty', 'sample_name', 'transcription', 'keywords', 'text'],\n    num_rows: 4999\n})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"dataset['text'][30]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T18:01:42.859786Z","iopub.execute_input":"2024-11-09T18:01:42.860078Z","iopub.status.idle":"2024-11-09T18:01:42.889798Z","shell.execute_reply.started":"2024-11-09T18:01:42.860043Z","shell.execute_reply":"2024-11-09T18:01:42.888928Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"\"<|im_start|>system\\n Followup left-sided rotator cuff tear and cervical spinal stenosis.  Physical examination and radiographic findings are compatible with left shoulder pain and left upper extremity pain, which is due to a combination of left-sided rotator cuff tear and moderate cervical spinal stenosis.<|im_end|>\\n<|im_start|>user\\nREASON FOR VISIT: , Followup left-sided rotator cuff tear and cervical spinal stenosis.,HISTORY OF PRESENT ILLNESS: , Ms. ABC returns today for followup regarding her left shoulder pain and left upper extremity C6 radiculopathy.  I had last seen her on 06/21/07.,At that time, she had been referred to me Dr. X and Dr. Y for evaluation of her left-sided C6 radiculopathy.  She also had a significant rotator cuff tear and is currently being evaluated for left-sided rotator cuff repair surgery, I believe on, approximately 07/20/07.  At our last visit, I only had a report of her prior cervical spine MRI.  I did not have any recent images.  I referred her for cervical spine MRI and she returns today.,She states that her symptoms are unchanged.  She continues to have significant left-sided shoulder pain for which she is being evaluated and is scheduled for surgery with Dr. Y.,She also has a second component of pain, which radiates down the left arm in a C6 distribution to the level of the wrist.  She has some associated minimal weakness described in detail in our prior office note.  No significant right upper extremity symptoms.  No bowel, bladder dysfunction.  No difficulty with ambulation.,FINDINGS: , On examination, she has 4 plus over 5 strength in the left biceps and triceps muscle groups, 4 out of 5 left deltoid, 5 out of 5 otherwise in both muscle groups and all muscle groups of upper extremities.  Light touch sensation is minimally decreased in the left C6 distribution; otherwise, intact.  Biceps and brachioradialis reflexes are 1 plus.  Hoffmann sign normal bilaterally.  Motor strength is 5 out of 5 in all muscle groups in lower extremities.  Hawkins and Neer impingement signs are positive at the left shoulder.,An EMG study performed on 06/08/07 demonstrates no evidence of radiculopathy or plexopathy or nerve entrapment to the left upper extremity.,Cervical spine MRI dated 06/28/07 is reviewed.  It is relatively limited study due to artifact.  He does demonstrate evidence of minimal-to-moderate stenosis at the C5-C6 level but without evidence of cord impingement or cord signal change.  There appears to be left paracentral disc herniation at the C5-C6 level, although axial T2-weighted images are quite limited.,ASSESSMENT AND PLAN: , Ms. ABC's history, physical examination and radiographic findings are compatible with left shoulder pain and left upper extremity pain, which is due to a combination of left-sided rotator cuff tear and moderate cervical spinal stenosis.,I agree with the plan to go ahead and continue with rotator cuff surgery.  With regard to the radiculopathy, I believe this can be treated non-operatively to begin with.  I am referring her for consideration of cervical epidural steroid injections.  The improvement in her pain may help her recover better from the shoulder surgery.,I will see her back in followup in 3 months, at which time she will be recovering from a shoulder surgery and we will see if she needs any further intervention with regard to the cervical spine.,I will also be in touch with Dr. Y to let him know this information prior to the surgery in several weeks.<|im_end|>\\n<|im_start|>assistant\\nsoap / chart / progress notes, upper extremity, radiculopathy, rotator cuff repair, cervical spinal stenosis, rotator cuff tear, physical examination, cuff, impingement, stenosis, extremity, surgery, tear, shoulder, rotator, cervical,<|im_end|>\\n\""},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"For model evaluation, we will split out the dataset into training and test split. ","metadata":{}},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T18:01:42.890980Z","iopub.execute_input":"2024-11-09T18:01:42.891305Z","iopub.status.idle":"2024-11-09T18:01:43.038334Z","shell.execute_reply.started":"2024-11-09T18:01:42.891246Z","shell.execute_reply":"2024-11-09T18:01:43.037414Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"training the model","metadata":{}},{"cell_type":"code","source":"# Setting Hyperparamter\ntraining_arguments = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=1,\n    optim=\"paged_adamw_32bit\",\n    num_train_epochs=2,\n    eval_strategy=\"steps\",\n    eval_steps=0.2,\n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"epoch\",\n    learning_rate=2e-4,\n    torch_empty_cache_steps = 500,\n    fp16=False,\n    bf16=False,\n    group_by_length=True,\n    save_strategy=\"epoch\",\n    report_to=\"wandb\",\n)\n# Setting sft parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    peft_config=peft_config,\n    max_seq_length= 512,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False,\n)\n\nmodel.config.use_cache = False\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T18:01:43.039359Z","iopub.execute_input":"2024-11-09T18:01:43.039677Z","iopub.status.idle":"2024-11-09T23:54:40.211285Z","shell.execute_reply.started":"2024-11-09T18:01:43.039645Z","shell.execute_reply":"2024-11-09T23:54:40.210408Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4499 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c58238aa664949a196fb2053ced45931"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d60c5276c1a46eba6737657b3e8aa45"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111356252222322, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33dd6f34019f4a6d887b3550df2216a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241109_180315-7do8n4wb</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/harishnair04-university-of-ottawa/huggingface/runs/7do8n4wb' target=\"_blank\">Gemma-medtr-2b-sft-v2</a></strong> to <a href='https://wandb.ai/harishnair04-university-of-ottawa/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/harishnair04-university-of-ottawa/huggingface' target=\"_blank\">https://wandb.ai/harishnair04-university-of-ottawa/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/harishnair04-university-of-ottawa/huggingface/runs/7do8n4wb' target=\"_blank\">https://wandb.ai/harishnair04-university-of-ottawa/huggingface/runs/7do8n4wb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8998' max='8998' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8998/8998 5:51:18, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1800</td>\n      <td>No log</td>\n      <td>1.695078</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>No log</td>\n      <td>1.524550</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>1.656600</td>\n      <td>1.373628</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>1.656600</td>\n      <td>1.259705</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=8998, training_loss=1.337776233260169, metrics={'train_runtime': 21163.5373, 'train_samples_per_second': 0.425, 'train_steps_per_second': 0.425, 'total_flos': 5.081403999852749e+16, 'train_loss': 1.337776233260169, 'epoch': 2.0})"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"evaluating the model performance","metadata":{}},{"cell_type":"code","source":"wandb.finish()\nmodel.config.use_cache = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T23:54:40.216775Z","iopub.execute_input":"2024-11-09T23:54:40.217070Z","iopub.status.idle":"2024-11-09T23:54:41.777401Z","shell.execute_reply.started":"2024-11-09T23:54:40.217038Z","shell.execute_reply":"2024-11-09T23:54:41.776619Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.028 MB of 0.028 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2a96221c8e040709cd164880c5396cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▃▁</td></tr><tr><td>eval/runtime</td><td>██▁▆</td></tr><tr><td>eval/samples_per_second</td><td>▁▁█▁</td></tr><tr><td>eval/steps_per_second</td><td>▁▁█▁</td></tr><tr><td>train/epoch</td><td>▁▃▄▅▆██</td></tr><tr><td>train/global_step</td><td>▁▃▄▅▆██</td></tr><tr><td>train/grad_norm</td><td>█▁</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.25971</td></tr><tr><td>eval/runtime</td><td>476.0954</td></tr><tr><td>eval/samples_per_second</td><td>1.05</td></tr><tr><td>eval/steps_per_second</td><td>1.05</td></tr><tr><td>total_flos</td><td>5.081403999852749e+16</td></tr><tr><td>train/epoch</td><td>2</td></tr><tr><td>train/global_step</td><td>8998</td></tr><tr><td>train/grad_norm</td><td>1.44129</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>1.019</td></tr><tr><td>train_loss</td><td>1.33778</td></tr><tr><td>train_runtime</td><td>21163.5373</td></tr><tr><td>train_samples_per_second</td><td>0.425</td></tr><tr><td>train_steps_per_second</td><td>0.425</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">Gemma-medtr-2b-sft-v2</strong> at: <a href='https://wandb.ai/harishnair04-university-of-ottawa/huggingface/runs/7do8n4wb' target=\"_blank\">https://wandb.ai/harishnair04-university-of-ottawa/huggingface/runs/7do8n4wb</a><br/> View project at: <a href='https://wandb.ai/harishnair04-university-of-ottawa/huggingface' target=\"_blank\">https://wandb.ai/harishnair04-university-of-ottawa/huggingface</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241109_180315-7do8n4wb/logs</code>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"trainer.model.save_pretrained(new_model)\ntrainer.model.push_to_hub(new_model, use_temp_dir=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T23:54:41.778522Z","iopub.execute_input":"2024-11-09T23:54:41.778839Z","iopub.status.idle":"2024-11-09T23:55:57.790675Z","shell.execute_reply.started":"2024-11-09T23:54:41.778804Z","shell.execute_reply":"2024-11-09T23:55:57.789742Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/2.40G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7895326449ba4642a5c0b44a30c6a84e"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/harishnair04/Gemma-medtr-2b-sft-v2/commit/a7b8f158c3518ccf1d91f60e69b9afdf13919c36', commit_message='Upload model', commit_description='', oid='a7b8f158c3518ccf1d91f60e69b9afdf13919c36', pr_url=None, repo_url=RepoUrl('https://huggingface.co/harishnair04/Gemma-medtr-2b-sft-v2', endpoint='https://huggingface.co', repo_type='model', repo_id='harishnair04/Gemma-medtr-2b-sft-v2'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# base_model_reload= AutoModelForCausalLM.from_pretrained(\n#     base_model,\n#     low_cpu_mem_usage=True,\n#     return_dict=True,\n#     torch_dtype=torch.bfloat16,\n#     device_map=\"cpu\",\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T23:55:57.791805Z","iopub.execute_input":"2024-11-09T23:55:57.792140Z","iopub.status.idle":"2024-11-09T23:55:57.797602Z","shell.execute_reply.started":"2024-11-09T23:55:57.792105Z","shell.execute_reply":"2024-11-09T23:55:57.796599Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained(base_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T23:55:57.798866Z","iopub.execute_input":"2024-11-09T23:55:57.799211Z","iopub.status.idle":"2024-11-09T23:55:57.815386Z","shell.execute_reply.started":"2024-11-09T23:55:57.799177Z","shell.execute_reply":"2024-11-09T23:55:57.814471Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# base_model_reload = setup_chat_format(base_model_reload)\n# model = PeftModel.from_pretrained(base_model_reload, \"/kaggle/working/Gemma-medtr-2b-sft-v1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T23:55:57.816432Z","iopub.execute_input":"2024-11-09T23:55:57.816728Z","iopub.status.idle":"2024-11-09T23:55:57.823287Z","shell.execute_reply.started":"2024-11-09T23:55:57.816696Z","shell.execute_reply":"2024-11-09T23:55:57.822384Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# tokenizer = setup_chat_format(tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T23:55:57.824487Z","iopub.execute_input":"2024-11-09T23:55:57.824873Z","iopub.status.idle":"2024-11-09T23:55:57.831017Z","shell.execute_reply.started":"2024-11-09T23:55:57.824841Z","shell.execute_reply":"2024-11-09T23:55:57.830283Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# model = model.merge_and_unload()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T23:55:57.832086Z","iopub.execute_input":"2024-11-09T23:55:57.832375Z","iopub.status.idle":"2024-11-09T23:55:57.838374Z","shell.execute_reply.started":"2024-11-09T23:55:57.832344Z","shell.execute_reply":"2024-11-09T23:55:57.837627Z"}},"outputs":[],"execution_count":20}]}